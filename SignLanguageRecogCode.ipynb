{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9098699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 Import dependecies\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "11ef6637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSV_Files_To_Video_Paths(file_data):\n",
    "    video_paths = []\n",
    "    label = []\n",
    "    for row in file_data:\n",
    "        row = row.split(\",\")\n",
    "        video_paths.append(row[3].strip().replace(\"/\", \"//\"))\n",
    "        label.append(row[1])\n",
    "    video_paths=video_paths[1:]\n",
    "    label = label[1:]\n",
    "    return video_paths,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "85b9958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #Colour Conversion BGR 2 RGB\n",
    "    image.flags.writeable = False                  #Image is no longer writeable\n",
    "    results = model.process(image)                 #Make predictions\n",
    "    image.flags.writeable = True                   #Image is writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) #Colour Conversion RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "a638d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    #right hand landmarks\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    #left hand landmarks\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    #pose landmarks\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "105c81b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose_array = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    left_hand_array = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    right_hand_array = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose_array, left_hand_array, right_hand_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_frame_func(frame):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "0e14d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation_frame_func(frame):\n",
    "    height, width = frame.shape[:2]\n",
    "    tx, ty = width / 4, height / 4\n",
    "# create the translation matrix using tx and ty, it is a NumPy array\n",
    "    translation_matrix = np.array([[1, 0, tx],\n",
    "                                   [0, 1, ty]], dtype=np.float32)\n",
    "    translated_image = cv2.warpAffine(src=frame, M=translation_matrix, dsize=(width, height))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "88250913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_vector_extract_from_video(video_path):\n",
    "    path_joiner = \"E://Mtech_Project_Code//Data//\"\n",
    "    Keypoints_for_video = []\n",
    "    flip_Keypoints_for_video = []\n",
    "    translation_Keypoints_for_video = []\n",
    "    ## 1. Read the video file\n",
    "    cap = cv2.VideoCapture(path_joiner+video_path)\n",
    "    if(cap.isOpened() == False):\n",
    "        print(\"Error opening the file :\", video_path)\n",
    "    # 2. Access Mediapipe model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:    \n",
    "        while(cap.isOpened()):\n",
    "            ret,frame = cap.read()\n",
    "            if ret == True:\n",
    "                #Data Augumentation\n",
    "                flip_frame = np.fliplr(frame)\n",
    "                #crop_frame = crop_frame_func(frame)\n",
    "                translation_frame = translation_frame_func(frame)\n",
    "                # 3. Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "                flip_image, flip_results = mediapipe_detection(flip_frame, holistic)\n",
    "                translation_image, translation_results = mediapipe_detection(translation_frame, holistic)\n",
    "                # 4. Draw landmarks\n",
    "                draw_landmarks(image, results)\n",
    "                draw_landmarks(flip_image, flip_results)\n",
    "                draw_landmarks(translation_image, translation_results)\n",
    "                # 5. Extract keypoints\n",
    "                keypoints_for_frame = extract_keypoints(results)\n",
    "                Keypoints_for_video.append(keypoints_for_frame)\n",
    "                \n",
    "                flip_keypoints_for_frame = extract_keypoints(flip_results)\n",
    "                flip_Keypoints_for_video.append(flip_keypoints_for_frame)\n",
    "                \n",
    "                translation_keypoints_for_frame = extract_keypoints(translation_results)\n",
    "                translation_Keypoints_for_video.append(translation_keypoints_for_frame)\n",
    "                #cv2.imshow('Frame', image)\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "               \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return [Keypoints_for_video, flip_Keypoints_for_video, translation_Keypoints_for_video]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "53efb37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "2295\n",
      "2295\n"
     ]
    }
   ],
   "source": [
    "##-----------------Main Class for train--------------------------\n",
    "\n",
    "## 1. Reading Train Data from Excel Sheet\n",
    "CSV_DataFile = (\"E://Mtech_Project_Code//train_include50.csv\") \n",
    "\n",
    "data =open(CSV_DataFile)\n",
    "video_paths_old,label_old=CSV_Files_To_Video_Paths(data)\n",
    "\n",
    "## 2. Weed out label and videos which can't be opened\n",
    "path_joiner = \"E://Mtech_Project_Code//Data//\"\n",
    "label=[]\n",
    "video_paths=[]\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "sequences = []\n",
    "i=0\n",
    "for i in range(len(video_paths_old)-1):\n",
    "    cap = cv2.VideoCapture(path_joiner+video_paths_old[i])\n",
    "    if(cap.isOpened() == False):\n",
    "        print(\"------>Error opening the file :\", video_paths_old[i])\n",
    "    else:\n",
    "        i=i+1\n",
    "        print(i)\n",
    "        sequence_list = feature_vector_extract_from_video(video_paths_old[i])\n",
    "        for sequence in sequence_list:\n",
    "            sequences.append(sequence)\n",
    "            label.append(label_old[i])\n",
    "            video_paths.append(video_paths_old[i])\n",
    "\n",
    "print(len(label))\n",
    "print(len(video_paths))\n",
    "## 3. KeyPoints using MP Holistic\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "cda3248f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205.93342776203966\n",
      "['4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '4.Bird', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '54.Black', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '11.Car', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '1.Dog', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '64.Fall', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '61.Father', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '51.GoodMorning', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '47.Red', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '61.Summer', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '55.White', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '1.loud', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '2.quiet', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '3.happy', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '78.long', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '79.short', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '83.biglarge', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '84.smalllittle', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '87.hot', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '91.new', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '97.dry', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '94.good', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '5.Cow', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '37.Hat', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '42.T-Shirt', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '44.Shoes', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '67.Monday', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '78.Year', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '86.Time', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '53.Fan', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '54.Cellphone', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '55.Thankyou', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '28.Window', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '34.Pen', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '40.Paint', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '84.Teacher', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '91.Priest', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '16.trainticket', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '66.Brother', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '77.Boy', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '78.Girl', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '23.Court', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '19.House', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '28.StoreorShop', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '35.Bank', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '40.I', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '44.it', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '46.you(plural)', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '14.Election', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death', '2.Death']\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "for i in sequences:\n",
    "    #print(np.array(i).shape)\n",
    "    n=n+np.array(i).shape[0]\n",
    "print(n/706)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "60ee6a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49474332,  0.31641191, -0.42638594, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.49968302,  0.31808954, -0.48941225, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.49735692,  0.31844771, -0.48935363, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_post[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "a350996e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2295, 154, 258)\n",
      "(2295, 154, 258)\n",
      "(2295, 63, 258)\n",
      "(2295, 63, 258)\n",
      "(2295,)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "padded_pre = pad_sequences(sequences, dtype='float64')\n",
    "padded_post = pad_sequences(sequences, padding= 'post', dtype='float64')\n",
    "truncated_pre = pad_sequences(sequences, maxlen=63, dtype='float64')\n",
    "truncated_post = pad_sequences(sequences, maxlen=63, truncating= 'post', dtype='float64')\n",
    "\n",
    "print(np.array(padded_pre).shape)\n",
    "print(np.array(padded_post).shape)\n",
    "print(np.array(truncated_pre).shape)\n",
    "print(np.array(truncated_post).shape)\n",
    "print(np.array(label).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "41a05048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "d7d0d905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "label_set = set(label_old)\n",
    "label_map = {label:num for num,label in enumerate(label_set)}\n",
    "for i in range(len(label)):\n",
    "    label[i]=label_map[label[i]]\n",
    "y=to_categorical(label).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "8d541295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "x=np.array(padded_post)\n",
    "y=to_categorical(label).astype(int)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "ae2360aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2295, 50)\n",
      "{'48.Hello': 0, '5.Cow': 1, '2.Death': 2, '14.Election': 3, '44.Shoes': 4, '1.loud': 5, '37.Hat': 6, '54.Cellphone': 7, '11.Car': 8, '55.White': 9, '53.Fan': 10, '87.hot': 11, '86.Time': 12, '78.Girl': 13, '40.I': 14, '83.biglarge': 15, '84.smalllittle': 16, '1.Dog': 17, '77.Boy': 18, '79.short': 19, '3.happy': 20, '61.Summer': 21, '19.House': 22, '97.dry': 23, '23.Court': 24, '47.Red': 25, '44.it': 26, '51.GoodMorning': 27, '4.Bird': 28, '94.good': 29, '64.Fall': 30, '34.Pen': 31, '35.Bank': 32, '42.T-Shirt': 33, '91.Priest': 34, '46.you(plural)': 35, '61.Father': 36, '84.Teacher': 37, '28.StoreorShop': 38, '54.Black': 39, '2.quiet': 40, '66.Brother': 41, '78.long': 42, '40.Paint': 43, '28.Window': 44, '67.Monday': 45, '78.Year': 46, '16.trainticket': 47, '55.Thankyou': 48, '91.new': 49}\n"
     ]
    }
   ],
   "source": [
    "print(np.array(y).shape)\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "eb599383",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de39d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1 :\n",
    "##--------------------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(16, return_sequences=True, implementation=2), input_shape=(154, 258)))\n",
    "model.add(TimeDistributed(Dense(8)))\n",
    "model.add(AveragePooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(label_set), activation='softmax'))\n",
    "# ---------------------------------------------------------------------\n",
    "model = Sequential(name = 'Simple_LSTM')\n",
    "model.add(LSTM(512,input_shape=(154, 258), recurrent_dropout=0.5))\n",
    "model.add(Dense(len(label_set),activation='softmax'))\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#-------------------------------------------------------------------------------\n",
    "model=Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,154,258)))\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "model.add(TimeDistributed(Dropout(0.5)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(len(label_set), activation='softmax'))\n",
    "#-------------------------------------------------------------------------------\n",
    "#trials :\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(128, return_sequences=True, activation='softmax', input_shape=(154,258)))\n",
    "# model.add(LSTM(64, return_sequences=False, activation='softmax'))\n",
    "# model.add(Dense(64, activation='softmax'))\n",
    "# model.add(Dense(32, activation='softmax'))\n",
    "# model.add(Dense(len(label_set), activation='softmax'))\n",
    "# model.add(LSTM(2, return_sequences=True, activation='relu', input_shape=(154,258)))\n",
    "# model.add(Dense(1, activation='relu'))\n",
    "# model.add(Dense(len(label_set), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc796d6",
   "metadata": {},
   "source": [
    "[batch_size, timesteps, features]\n",
    "the number of hidden units\n",
    "hidden = samples/x *(i+o) ; \n",
    "5\n",
    "2/3*(i+o)\n",
    "205\n",
    "-----\n",
    "Calculate batch size\n",
    "using different batch size while prediction in training and testing\n",
    "first define model, old_weights = model.get_weights()\n",
    "new_model.set_weights(old_weights)\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "bb2a5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import AveragePooling1D\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "verbose, epochs, batch_size = 0, 25, 64\n",
    "n_timesteps, n_features, n_outputs = Xtrain.shape[1], Xtrain.shape[2], ytrain.shape[1]\n",
    "# reshape into subsequences (samples, time steps, rows, cols, channels)\n",
    "n_steps, n_length = 7, 22\n",
    "\n",
    "model1 = Sequential(name = 'Simple_LSTM')\n",
    "model1.add(LSTM(64,input_shape=(154, 258), recurrent_dropout=0.5))\n",
    "model1.add(Dense(len(label_set),activation='softmax'))\n",
    "model1.compile(optimizer=optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#------------------------------------------------------------------------------------------\n",
    "model2= Sequential()\n",
    "\n",
    "model2.add(ConvLSTM2D(filters=128, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, n_features)))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dense(n_outputs, activation='softmax'))\n",
    "#-----------------------------------------------------------------------\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(128, return_sequences=True, activation='softmax', input_shape=(154,258)))\n",
    "# model.add(LSTM(64, return_sequences=False, activation='softmax'))\n",
    "# model.add(Dense(64, activation='softmax'))\n",
    "# model.add(Dense(32, activation='softmax'))\n",
    "# model.add(Dense(len(label_set), activation='softmax'))\n",
    "##--------------------------------------------------------------------\n",
    "model3 = Sequential()\n",
    "model3.add(Bidirectional(LSTM(16, return_sequences=True, implementation=2), input_shape=(154, 258)))\n",
    "model3.add(TimeDistributed(Dense(8)))\n",
    "model3.add(AveragePooling1D())\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(len(label_set), activation='softmax'))\n",
    "# # ---------------------------------------------------------------------\n",
    "# model.add(LSTM(2, return_sequences=True, activation='relu', input_shape=(154,258)))\n",
    "# model.add(Dense(1, activation='relu'))\n",
    "# model.add(Dense(len(label_set), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "3851fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(n_steps, n_length, n_features)))\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "model.add(TimeDistributed(Dropout(0.5)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(label_set), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "20797064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "from keras import optimizers\n",
    "optimizer = optimizers.Adam(clipvalue=1.0, lr=0.001)\n",
    "model2.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "fda28375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537\n",
      "Epoch 1/200\n",
      "1537/1537 [==============================] - 4s - loss: 3.9015 - acc: 0.0163     \n",
      "Epoch 2/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.8897 - acc: 0.0280     \n",
      "Epoch 3/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.8738 - acc: 0.0312     \n",
      "Epoch 4/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.8554 - acc: 0.0403     \n",
      "Epoch 5/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.8307 - acc: 0.0553     \n",
      "Epoch 6/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.7935 - acc: 0.0481     \n",
      "Epoch 7/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.7523 - acc: 0.0605     \n",
      "Epoch 8/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.7033 - acc: 0.0644     \n",
      "Epoch 9/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.6514 - acc: 0.0709     \n",
      "Epoch 10/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.7122 - acc: 0.0612     \n",
      "Epoch 11/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.6715 - acc: 0.0618     \n",
      "Epoch 12/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.6419 - acc: 0.0742     \n",
      "Epoch 13/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.5919 - acc: 0.0683     \n",
      "Epoch 14/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.5337 - acc: 0.0846     \n",
      "Epoch 15/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.4209 - acc: 0.1067     \n",
      "Epoch 16/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.2778 - acc: 0.1015     \n",
      "Epoch 17/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.6033 - acc: 0.0696     \n",
      "Epoch 18/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.3929 - acc: 0.1054     \n",
      "Epoch 19/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.1871 - acc: 0.1223     \n",
      "Epoch 20/200\n",
      "1537/1537 [==============================] - 3s - loss: 3.0393 - acc: 0.1230     \n",
      "Epoch 21/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.9663 - acc: 0.1457     \n",
      "Epoch 22/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.9235 - acc: 0.1522     \n",
      "Epoch 23/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.8561 - acc: 0.1659     \n",
      "Epoch 24/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.7929 - acc: 0.1718     \n",
      "Epoch 25/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.7561 - acc: 0.1965     \n",
      "Epoch 26/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.6675 - acc: 0.2004     \n",
      "Epoch 27/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.6808 - acc: 0.1932     \n",
      "Epoch 28/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.6282 - acc: 0.2030     \n",
      "Epoch 29/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.6871 - acc: 0.2128     \n",
      "Epoch 30/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.5445 - acc: 0.2251     \n",
      "Epoch 31/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.5342 - acc: 0.2225     \n",
      "Epoch 32/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.5067 - acc: 0.2440     \n",
      "Epoch 33/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.4262 - acc: 0.2661     \n",
      "Epoch 34/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.4938 - acc: 0.2492     \n",
      "Epoch 35/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.3913 - acc: 0.2707     \n",
      "Epoch 36/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.3434 - acc: 0.2902     \n",
      "Epoch 37/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.3409 - acc: 0.2811     \n",
      "Epoch 38/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.2260 - acc: 0.3110     \n",
      "Epoch 39/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.2161 - acc: 0.3247     \n",
      "Epoch 40/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.2476 - acc: 0.3090     \n",
      "Epoch 41/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.1711 - acc: 0.3312     \n",
      "Epoch 42/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.2982 - acc: 0.2980     \n",
      "Epoch 43/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.1259 - acc: 0.3494     \n",
      "Epoch 44/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.0876 - acc: 0.3598     \n",
      "Epoch 45/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.0207 - acc: 0.3689     \n",
      "Epoch 46/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.0741 - acc: 0.3663     \n",
      "Epoch 47/200\n",
      "1537/1537 [==============================] - 3s - loss: 2.0074 - acc: 0.3813     \n",
      "Epoch 48/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.9627 - acc: 0.3897     \n",
      "Epoch 49/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.9062 - acc: 0.4092     \n",
      "Epoch 50/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.8632 - acc: 0.4183     \n",
      "Epoch 51/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.8283 - acc: 0.4294     \n",
      "Epoch 52/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.8285 - acc: 0.4236     \n",
      "Epoch 53/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.8042 - acc: 0.4275     \n",
      "Epoch 54/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.7546 - acc: 0.4418     \n",
      "Epoch 55/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.6736 - acc: 0.4626     \n",
      "Epoch 56/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.6848 - acc: 0.4802     \n",
      "Epoch 57/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.7028 - acc: 0.4717     \n",
      "Epoch 58/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.9078 - acc: 0.4131     \n",
      "Epoch 59/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.7146 - acc: 0.4483     \n",
      "Epoch 60/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.8754 - acc: 0.4203     \n",
      "Epoch 61/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.7838 - acc: 0.4437     \n",
      "Epoch 62/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.5973 - acc: 0.4945     \n",
      "Epoch 63/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.4974 - acc: 0.5355     \n",
      "Epoch 64/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.5418 - acc: 0.5094     \n",
      "Epoch 65/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.5530 - acc: 0.5146     \n",
      "Epoch 66/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.5481 - acc: 0.5055     \n",
      "Epoch 67/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.5010 - acc: 0.5270     \n",
      "Epoch 68/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.4102 - acc: 0.5634     \n",
      "Epoch 69/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.4560 - acc: 0.5355     \n",
      "Epoch 70/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.4464 - acc: 0.5387     \n",
      "Epoch 71/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.3711 - acc: 0.5673     \n",
      "Epoch 72/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.2782 - acc: 0.5908     \n",
      "Epoch 73/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.2404 - acc: 0.6083     \n",
      "Epoch 74/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.2624 - acc: 0.5940     \n",
      "Epoch 75/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.2854 - acc: 0.5999     \n",
      "Epoch 76/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.5809 - acc: 0.4971     \n",
      "Epoch 77/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.3552 - acc: 0.5621     \n",
      "Epoch 78/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.3688 - acc: 0.5504     \n",
      "Epoch 79/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.2083 - acc: 0.6122     \n",
      "Epoch 80/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.2466 - acc: 0.6031     \n",
      "Epoch 81/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.1540 - acc: 0.6226     \n",
      "Epoch 82/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.1472 - acc: 0.6389     \n",
      "Epoch 83/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.3831 - acc: 0.5667     \n",
      "Epoch 84/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.2768 - acc: 0.5992     \n",
      "Epoch 85/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.0922 - acc: 0.6558     \n",
      "Epoch 86/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.0801 - acc: 0.6675     \n",
      "Epoch 87/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.0707 - acc: 0.6617     \n",
      "Epoch 88/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.0244 - acc: 0.6695     \n",
      "Epoch 89/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.0033 - acc: 0.6643     \n",
      "Epoch 90/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.0742 - acc: 0.6669     \n",
      "Epoch 91/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.9865 - acc: 0.6916     \n",
      "Epoch 92/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.9418 - acc: 0.7085     \n",
      "Epoch 93/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.8808 - acc: 0.7248     \n",
      "Epoch 94/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.0261 - acc: 0.6727     \n",
      "Epoch 95/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.9227 - acc: 0.7105     - ETA: 1s - loss: 0.886\n",
      "Epoch 96/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.9210 - acc: 0.6831     \n",
      "Epoch 97/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.8387 - acc: 0.7443     \n",
      "Epoch 98/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.8867 - acc: 0.7131     \n",
      "Epoch 99/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.8042 - acc: 0.7593     \n",
      "Epoch 100/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.8324 - acc: 0.7345     \n",
      "Epoch 101/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.8994 - acc: 0.7170     \n",
      "Epoch 102/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.8658 - acc: 0.7267     \n",
      "Epoch 103/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.7869 - acc: 0.7541     \n",
      "Epoch 104/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.8723 - acc: 0.7196     \n",
      "Epoch 105/200\n",
      "1537/1537 [==============================] - 3s - loss: 1.0410 - acc: 0.6675     \n",
      "Epoch 106/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.9442 - acc: 0.6877     \n",
      "Epoch 107/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.7860 - acc: 0.7430     \n",
      "Epoch 108/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.9307 - acc: 0.7157     \n",
      "Epoch 109/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.7922 - acc: 0.7437     \n",
      "Epoch 110/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.7686 - acc: 0.7469     \n",
      "Epoch 111/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.8133 - acc: 0.7437     \n",
      "Epoch 112/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.7886 - acc: 0.7372     \n",
      "Epoch 113/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.7041 - acc: 0.7742     \n",
      "Epoch 114/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.6651 - acc: 0.7892     \n",
      "Epoch 115/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.6589 - acc: 0.7820     \n",
      "Epoch 116/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.6551 - acc: 0.8061     \n",
      "Epoch 117/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.6675 - acc: 0.7866     \n",
      "Epoch 118/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.5903 - acc: 0.8256     \n",
      "Epoch 119/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.5798 - acc: 0.8126     \n",
      "Epoch 120/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.6047 - acc: 0.8178     \n",
      "Epoch 121/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.8430 - acc: 0.7319     \n",
      "Epoch 122/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.6493 - acc: 0.7931     \n",
      "Epoch 123/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.8629 - acc: 0.7137     \n",
      "Epoch 124/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.7003 - acc: 0.7755     \n",
      "Epoch 125/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.7528 - acc: 0.7580     \n",
      "Epoch 126/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.6598 - acc: 0.7801     \n",
      "Epoch 127/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.6477 - acc: 0.7885     \n",
      "Epoch 128/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.5943 - acc: 0.8048     \n",
      "Epoch 129/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.5327 - acc: 0.8295     \n",
      "Epoch 130/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.5275 - acc: 0.8250     \n",
      "Epoch 131/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4651 - acc: 0.8582     \n",
      "Epoch 132/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4750 - acc: 0.8575     \n",
      "Epoch 133/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4705 - acc: 0.8523     \n",
      "Epoch 134/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.5906 - acc: 0.8204     \n",
      "Epoch 135/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.5132 - acc: 0.8302     \n",
      "Epoch 136/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.5407 - acc: 0.8230     \n",
      "Epoch 137/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4639 - acc: 0.8627     \n",
      "Epoch 138/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4531 - acc: 0.8627     \n",
      "Epoch 139/200\n",
      "1537/1537 [==============================] - ETA: 0s - loss: 0.4646 - acc: 0.859 - 3s - loss: 0.4645 - acc: 0.8595     \n",
      "Epoch 140/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4547 - acc: 0.8543     \n",
      "Epoch 141/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.8319 - acc: 0.7430     \n",
      "Epoch 142/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.7191 - acc: 0.7684     \n",
      "Epoch 143/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.5672 - acc: 0.8178     \n",
      "Epoch 144/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4754 - acc: 0.8432     \n",
      "Epoch 145/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4085 - acc: 0.8705     \n",
      "Epoch 146/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4198 - acc: 0.8712     \n",
      "Epoch 147/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4070 - acc: 0.8796     \n",
      "Epoch 148/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3923 - acc: 0.8861     \n",
      "Epoch 149/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3719 - acc: 0.8868     \n",
      "Epoch 150/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3750 - acc: 0.8874     \n",
      "Epoch 151/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3616 - acc: 0.8881     \n",
      "Epoch 152/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3598 - acc: 0.8926     \n",
      "Epoch 153/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4772 - acc: 0.8504     \n",
      "Epoch 154/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4079 - acc: 0.8751     \n",
      "Epoch 155/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.5256 - acc: 0.8367     \n",
      "Epoch 156/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4141 - acc: 0.8601     \n",
      "Epoch 157/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.8343 - acc: 0.7560     \n",
      "Epoch 158/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.5285 - acc: 0.8426     \n",
      "Epoch 159/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.9012 - acc: 0.7163     \n",
      "Epoch 160/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.6114 - acc: 0.7983     \n",
      "Epoch 161/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4795 - acc: 0.8439     \n",
      "Epoch 162/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.5400 - acc: 0.8224     \n",
      "Epoch 163/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4293 - acc: 0.8738     \n",
      "Epoch 164/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3765 - acc: 0.8868     \n",
      "Epoch 165/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3227 - acc: 0.9044     \n",
      "Epoch 166/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3139 - acc: 0.9089     \n",
      "Epoch 167/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3352 - acc: 0.9063     \n",
      "Epoch 168/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3290 - acc: 0.9063     \n",
      "Epoch 169/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3123 - acc: 0.9128     \n",
      "Epoch 170/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4497 - acc: 0.8621     \n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 [==============================] - 3s - loss: 0.4656 - acc: 0.8556     \n",
      "Epoch 172/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.4301 - acc: 0.8608     \n",
      "Epoch 173/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3780 - acc: 0.8855     \n",
      "Epoch 174/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3520 - acc: 0.8933     \n",
      "Epoch 175/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3157 - acc: 0.9005     \n",
      "Epoch 176/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2820 - acc: 0.9141     \n",
      "Epoch 177/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2915 - acc: 0.9076     \n",
      "Epoch 178/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2585 - acc: 0.9239     \n",
      "Epoch 179/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2634 - acc: 0.9206     \n",
      "Epoch 180/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2719 - acc: 0.9148     \n",
      "Epoch 181/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2474 - acc: 0.9226     \n",
      "Epoch 182/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2621 - acc: 0.9148     \n",
      "Epoch 183/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2987 - acc: 0.9076     \n",
      "Epoch 184/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2459 - acc: 0.9284     \n",
      "Epoch 185/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2437 - acc: 0.9369     \n",
      "Epoch 186/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2280 - acc: 0.9375     \n",
      "Epoch 187/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3469 - acc: 0.8907     \n",
      "Epoch 188/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3912 - acc: 0.8738     \n",
      "Epoch 189/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2613 - acc: 0.9252     \n",
      "Epoch 190/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2793 - acc: 0.9096     \n",
      "Epoch 191/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2358 - acc: 0.9297     \n",
      "Epoch 192/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2199 - acc: 0.9330     \n",
      "Epoch 193/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2199 - acc: 0.9330     \n",
      "Epoch 194/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.3019 - acc: 0.9083     \n",
      "Epoch 195/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2351 - acc: 0.9310     \n",
      "Epoch 196/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2351 - acc: 0.9271     \n",
      "Epoch 197/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2740 - acc: 0.9167     \n",
      "Epoch 198/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2784 - acc: 0.9174     \n",
      "Epoch 199/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2496 - acc: 0.9271     \n",
      "Epoch 200/200\n",
      "1537/1537 [==============================] - 3s - loss: 0.2517 - acc: 0.9304     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1684e09b6a0>"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(Xtrain.shape[0])\n",
    "trainX = Xtrain.reshape((Xtrain.shape[0], n_steps, n_length, n_features))\n",
    "testX = Xtest.reshape((Xtest.shape[0], n_steps, n_length, n_features))\n",
    "# model2.fit(trainX,ytrain, batch_size=64, epochs=200, callbacks=[tb_callback])\n",
    "# model3.fit(Xtrain,ytrain, batch_size=64, epochs=200, callbacks=[tb_callback])\n",
    "model.fit(trainX,ytrain, batch_size=64, epochs=200, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "ef9b70ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['61.Summer', '78.Year', '64.Fall', '91.Priest', '84.Teacher', '14.Election', '55.White', '91.Priest', '54.Black', '34.Pen', '67.Monday', '3.happy', '40.I', '5.Cow', '53.Fan', '2.Death', '79.short', '91.new', '61.Summer', '61.Summer', '87.hot', '86.Time', '84.Teacher', '66.Brother', '40.Paint', '61.Summer', '23.Court', '42.T-Shirt', '91.Priest', '54.Black', '78.long', '91.new', '35.Bank', '83.biglarge', '87.hot', '66.Brother', '4.Bird', '4.Bird', '51.GoodMorning', '64.Fall', '3.happy', '3.happy', '28.StoreorShop', '42.T-Shirt', '42.T-Shirt', '83.biglarge', '86.Time', '84.Teacher', '40.I', '84.smalllittle', '28.StoreorShop', '67.Monday', '53.Fan', '86.Time', '28.Window', '37.Hat', '19.House', '1.Dog', '91.Priest', '77.Boy', '42.T-Shirt', '11.Car', '78.long', '42.T-Shirt', '54.Cellphone', '55.White', '79.short', '94.good', '37.Hat', '3.happy', '78.long', '35.Bank', '83.biglarge', '67.Monday', '83.biglarge', '77.Boy', '46.you(plural)', '1.loud', '3.happy', '2.quiet', '55.Thankyou', '51.GoodMorning', '53.Fan', '44.it', '28.Window', '78.long', '23.Court', '77.Boy', '78.long', '61.Father', '4.Bird', '48.Hello', '78.Girl', '61.Summer', '40.Paint', '2.Death', '37.Hat', '40.Paint', '1.loud', '61.Summer', '55.Thankyou', '51.GoodMorning', '3.happy', '44.Shoes', '91.Priest', '28.StoreorShop', '87.hot', '55.White', '2.quiet', '16.trainticket', '5.Cow', '61.Father', '28.StoreorShop', '55.White', '84.Teacher', '54.Black', '42.T-Shirt', '44.it', '47.Red', '55.White', '23.Court', '97.dry', '97.dry', '23.Court', '44.it', '5.Cow', '55.White', '40.Paint', '1.Dog', '34.Pen', '91.Priest', '78.long', '47.Red', '48.Hello', '67.Monday', '55.White', '67.Monday', '91.Priest', '61.Summer', '19.House', '46.you(plural)', '67.Monday', '40.Paint', '97.dry', '40.I', '84.Teacher', '1.Dog', '1.loud', '28.StoreorShop', '2.Death', '46.you(plural)', '86.Time', '97.dry', '46.you(plural)', '91.new', '91.new', '91.Priest', '54.Black', '40.Paint', '28.StoreorShop', '78.Girl', '47.Red', '44.Shoes', '87.hot', '78.Girl', '42.T-Shirt', '86.Time', '42.T-Shirt', '40.Paint', '55.Thankyou', '84.smalllittle', '35.Bank', '47.Red', '83.biglarge', '66.Brother', '55.White', '2.quiet', '40.I', '42.T-Shirt', '34.Pen', '4.Bird', '66.Brother', '19.House', '84.Teacher', '94.good', '61.Father', '78.Girl', '97.dry', '4.Bird', '86.Time', '66.Brother', '19.House', '97.dry', '61.Father', '79.short', '64.Fall', '35.Bank', '78.long', '23.Court', '53.Fan', '28.Window', '47.Red', '40.I', '61.Summer', '34.Pen', '54.Black', '19.House', '23.Court', '48.Hello', '44.Shoes', '19.House', '97.dry', '55.White', '2.quiet', '54.Cellphone', '97.dry', '35.Bank', '97.dry', '83.biglarge', '54.Cellphone', '34.Pen', '64.Fall', '77.Boy', '23.Court', '37.Hat', '54.Black', '28.Window', '28.StoreorShop', '1.Dog', '23.Court', '54.Black', '2.quiet', '54.Black', '91.Priest', '3.happy', '86.Time', '19.House', '47.Red', '78.Girl', '46.you(plural)', '61.Father', '44.it', '4.Bird', '84.smalllittle', '48.Hello', '5.Cow', '97.dry', '84.Teacher', '2.Death', '61.Father', '84.smalllittle', '61.Summer', '61.Father', '46.you(plural)', '2.quiet', '55.White', '55.White', '46.you(plural)', '16.trainticket', '4.Bird', '40.I', '53.Fan', '79.short', '87.hot', '91.Priest', '54.Black', '5.Cow', '23.Court', '28.StoreorShop', '83.biglarge', '1.Dog', '51.GoodMorning', '1.loud', '37.Hat', '3.happy', '55.Thankyou', '1.loud', '46.you(plural)', '48.Hello', '55.Thankyou', '55.White', '40.I', '66.Brother', '64.Fall', '11.Car', '4.Bird', '78.Girl', '84.smalllittle', '94.good', '37.Hat', '1.Dog', '61.Father', '55.Thankyou', '53.Fan', '67.Monday', '16.trainticket', '91.new', '11.Car', '91.new', '64.Fall', '23.Court', '86.Time', '40.I', '83.biglarge', '48.Hello', '67.Monday', '3.happy', '1.Dog', '78.Girl', '28.StoreorShop', '78.Girl', '55.Thankyou', '51.GoodMorning', '79.short', '78.Girl', '1.loud', '28.StoreorShop', '55.White', '44.it', '44.it', '1.Dog', '84.smalllittle', '84.smalllittle', '44.it', '44.Shoes', '91.Priest', '55.White', '5.Cow', '84.smalllittle', '16.trainticket', '61.Summer', '94.good', '28.StoreorShop', '91.Priest', '5.Cow', '53.Fan', '37.Hat', '54.Cellphone', '5.Cow', '54.Cellphone', '87.hot', '5.Cow', '1.loud', '1.Dog', '91.Priest', '11.Car', '61.Father', '40.Paint', '19.House', '78.Year', '44.it', '1.loud', '61.Father', '78.long', '78.long', '34.Pen', '55.White', '48.Hello', '19.House', '84.Teacher', '3.happy', '19.House', '54.Cellphone', '78.Year', '94.good', '3.happy', '14.Election', '1.Dog', '54.Cellphone', '28.Window', '2.quiet', '40.Paint', '53.Fan', '78.long', '83.biglarge', '78.long', '87.hot', '78.Girl', '1.loud', '64.Fall', '14.Election', '48.Hello', '3.happy', '79.short', '5.Cow', '34.Pen', '51.GoodMorning', '23.Court', '47.Red', '1.loud', '67.Monday', '55.White', '51.GoodMorning', '55.White', '61.Father', '54.Black', '54.Cellphone', '61.Father', '47.Red', '1.loud', '84.smalllittle', '94.good', '79.short', '5.Cow', '94.good', '28.Window', '66.Brother', '11.Car', '28.StoreorShop', '1.Dog', '97.dry', '55.White', '35.Bank', '40.Paint', '54.Cellphone', '4.Bird', '44.Shoes', '47.Red', '2.quiet', '91.new', '42.T-Shirt', '40.I', '2.Death', '37.Hat', '4.Bird', '35.Bank', '84.smalllittle', '46.you(plural)', '78.Year', '64.Fall', '2.Death', '78.Girl', '40.I', '4.Bird', '40.I', '64.Fall', '55.Thankyou', '14.Election', '35.Bank', '28.StoreorShop', '28.StoreorShop', '46.you(plural)', '78.Girl', '48.Hello', '14.Election', '28.StoreorShop', '40.I', '40.I', '16.trainticket', '94.good', '47.Red', '78.Girl', '47.Red', '3.happy', '19.House', '64.Fall', '23.Court', '34.Pen', '46.you(plural)', '51.GoodMorning', '51.GoodMorning', '23.Court', '87.hot', '67.Monday', '11.Car', '64.Fall', '84.smalllittle', '78.Year', '28.StoreorShop', '61.Father', '97.dry', '40.I', '35.Bank', '83.biglarge', '55.Thankyou', '91.new', '77.Boy', '55.White', '5.Cow', '91.new', '91.new', '87.hot', '4.Bird', '47.Red', '78.Girl', '51.GoodMorning', '84.Teacher', '40.Paint', '77.Boy', '61.Summer', '3.happy', '19.House', '34.Pen', '47.Red', '55.Thankyou', '16.trainticket', '66.Brother', '37.Hat', '47.Red', '97.dry', '28.StoreorShop', '86.Time', '5.Cow', '79.short', '2.Death', '1.Dog', '94.good', '19.House', '64.Fall', '23.Court', '44.Shoes', '94.good', '78.long', '84.Teacher', '66.Brother', '4.Bird', '51.GoodMorning', '19.House', '61.Summer', '54.Black', '91.Priest', '11.Car', '78.Year', '2.quiet', '48.Hello', '55.Thankyou', '11.Car', '78.Year', '44.it', '3.happy', '79.short', '35.Bank', '83.biglarge', '94.good', '84.Teacher', '40.I', '54.Black', '54.Cellphone', '46.you(plural)', '86.Time', '86.Time', '14.Election', '78.Year', '2.quiet', '55.Thankyou', '1.loud', '37.Hat', '35.Bank', '78.Year', '42.T-Shirt', '54.Black', '4.Bird', '66.Brother', '28.StoreorShop', '37.Hat', '46.you(plural)', '44.Shoes', '37.Hat', '67.Monday', '87.hot', '77.Boy', '64.Fall', '83.biglarge', '5.Cow', '23.Court', '28.Window', '2.quiet', '28.StoreorShop', '23.Court', '1.Dog', '2.quiet', '5.Cow', '1.loud', '51.GoodMorning', '40.I', '4.Bird', '86.Time', '64.Fall', '16.trainticket', '83.biglarge', '67.Monday', '1.Dog', '5.Cow', '86.Time', '3.happy', '61.Father', '78.Girl', '91.Priest', '78.Girl', '23.Court', '66.Brother', '4.Bird', '46.you(plural)', '47.Red', '2.quiet', '91.new', '28.StoreorShop', '54.Black', '97.dry', '53.Fan', '44.Shoes', '61.Father', '84.smalllittle', '42.T-Shirt', '87.hot', '97.dry', '87.hot', '3.happy', '55.White', '5.Cow', '84.Teacher', '19.House', '55.White', '54.Black', '4.Bird', '35.Bank', '28.Window', '35.Bank', '47.Red', '97.dry', '23.Court', '34.Pen', '51.GoodMorning', '64.Fall', '91.Priest', '54.Cellphone', '2.Death', '87.hot', '83.biglarge', '78.Girl', '77.Boy', '14.Election', '14.Election', '55.White', '48.Hello', '61.Father', '5.Cow', '64.Fall', '5.Cow', '2.quiet', '61.Summer', '78.Girl', '23.Court', '3.happy', '44.Shoes', '66.Brother', '44.Shoes', '78.Year', '97.dry', '55.White', '87.hot', '48.Hello', '16.trainticket', '53.Fan', '77.Boy', '4.Bird', '19.House', '37.Hat', '51.GoodMorning', '91.Priest', '3.happy', '78.Girl', '78.long', '46.you(plural)', '78.Girl', '55.White', '48.Hello', '47.Red', '19.House', '2.quiet', '4.Bird', '42.T-Shirt', '55.Thankyou', '19.House', '86.Time', '48.Hello', '28.StoreorShop', '77.Boy', '78.Year', '47.Red', '2.quiet', '48.Hello', '78.long', '97.dry', '2.Death', '47.Red', '54.Black', '94.good', '78.Girl', '44.it', '23.Court', '61.Father', '2.Death', '79.short', '23.Court', '2.quiet', '79.short', '40.Paint', '77.Boy', '40.Paint', '91.new', '34.Pen', '51.GoodMorning', '44.Shoes', '77.Boy', '94.good', '87.hot', '51.GoodMorning', '66.Brother', '55.White', '3.happy', '1.Dog', '77.Boy', '5.Cow', '4.Bird', '11.Car', '83.biglarge', '47.Red', '94.good', '91.new', '4.Bird', '55.White', '28.StoreorShop', '19.House', '51.GoodMorning', '1.Dog', '44.it', '46.you(plural)', '3.happy', '51.GoodMorning', '78.Girl', '61.Father', '94.good', '78.Girl', '2.quiet', '19.House', '91.new', '23.Court', '78.Girl', '84.smalllittle', '91.new', '34.Pen', '5.Cow', '78.Year', '46.you(plural)', '55.Thankyou', '2.quiet', '19.House', '28.StoreorShop', '94.good', '40.I', '23.Court', '66.Brother', '4.Bird', '44.Shoes', '78.Year', '1.loud', '83.biglarge']\n",
      "['48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello', '48.Hello']\n",
      "Stacked Test Accuracy: 0.020\n"
     ]
    }
   ],
   "source": [
    "def get_key(a,b):\n",
    "    return [k for k,v in a.items() if v == b][0]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from numpy import dstack\n",
    "stackX = None\n",
    "stackX = model2.predict(testX,verbose=0)\n",
    "stackX = dstack((stackX, model3.predict(Xtest, verbose=0)))\n",
    "stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
    "model = LogisticRegression()\n",
    "y_test_label = []\n",
    "for i in ytest:\n",
    "    y_test_label.append(get_key(label_map,np.argmax(i)))\n",
    "\n",
    "model.fit(stackX, y_test_label)\n",
    "yhat = model.predict(stackX)\n",
    "y_hat_label = []\n",
    "for i in yhat:\n",
    "    y_hat_label.append(get_key(label_map,np.argmax(i)))\n",
    "print(y_test_label)\n",
    "print(y_hat_label)\n",
    "acc = accuracy_score(y_test_label, y_hat_label)\n",
    "print('Stacked Test Accuracy: %.3f' % acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "55c714d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_77 (TimeDis (None, 7, 20, 64)         49600     \n",
      "_________________________________________________________________\n",
      "time_distributed_78 (TimeDis (None, 7, 18, 64)         12352     \n",
      "_________________________________________________________________\n",
      "time_distributed_79 (TimeDis (None, 7, 18, 64)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_80 (TimeDis (None, 7, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_81 (TimeDis (None, 7, 576)            0         \n",
      "_________________________________________________________________\n",
      "lstm_114 (LSTM)              (None, 64)                164096    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 229,778\n",
      "Trainable params: 229,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "42251576",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=model.predict(testX)\n",
    "ytrue = np.argmax(ytest, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "70873376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[736,   7],\n",
       "        [  6,   9]],\n",
       "\n",
       "       [[736,   1],\n",
       "        [  3,  18]],\n",
       "\n",
       "       [[745,   3],\n",
       "        [  2,   8]],\n",
       "\n",
       "       [[746,   4],\n",
       "        [  1,   7]],\n",
       "\n",
       "       [[743,   3],\n",
       "        [  3,   9]],\n",
       "\n",
       "       [[744,   0],\n",
       "        [  4,  10]],\n",
       "\n",
       "       [[745,   0],\n",
       "        [  9,   4]],\n",
       "\n",
       "       [[741,   6],\n",
       "        [  7,   4]],\n",
       "\n",
       "       [[747,   2],\n",
       "        [  0,   9]],\n",
       "\n",
       "       [[722,  10],\n",
       "        [ 19,   7]],\n",
       "\n",
       "       [[736,  12],\n",
       "        [  1,   9]],\n",
       "\n",
       "       [[731,  12],\n",
       "        [  5,  10]],\n",
       "\n",
       "       [[739,   5],\n",
       "        [  6,   8]],\n",
       "\n",
       "       [[716,  18],\n",
       "        [ 11,  13]],\n",
       "\n",
       "       [[731,  10],\n",
       "        [  4,  13]],\n",
       "\n",
       "       [[735,   7],\n",
       "        [  0,  16]],\n",
       "\n",
       "       [[744,   1],\n",
       "        [  2,  11]],\n",
       "\n",
       "       [[740,   2],\n",
       "        [  9,   7]],\n",
       "\n",
       "       [[729,  16],\n",
       "        [  7,   6]],\n",
       "\n",
       "       [[745,   2],\n",
       "        [  3,   8]],\n",
       "\n",
       "       [[731,   6],\n",
       "        [  1,  20]],\n",
       "\n",
       "       [[736,   9],\n",
       "        [ 10,   3]],\n",
       "\n",
       "       [[736,   1],\n",
       "        [  5,  16]],\n",
       "\n",
       "       [[736,   4],\n",
       "        [  5,  13]],\n",
       "\n",
       "       [[731,   4],\n",
       "        [  0,  23]],\n",
       "\n",
       "       [[727,  11],\n",
       "        [ 16,   4]],\n",
       "\n",
       "       [[743,   4],\n",
       "        [  6,   5]],\n",
       "\n",
       "       [[734,   6],\n",
       "        [ 12,   6]],\n",
       "\n",
       "       [[734,   2],\n",
       "        [  2,  20]],\n",
       "\n",
       "       [[736,   6],\n",
       "        [  8,   8]],\n",
       "\n",
       "       [[738,   4],\n",
       "        [ 15,   1]],\n",
       "\n",
       "       [[742,   4],\n",
       "        [  5,   7]],\n",
       "\n",
       "       [[743,   2],\n",
       "        [  4,   9]],\n",
       "\n",
       "       [[737,   8],\n",
       "        [  1,  12]],\n",
       "\n",
       "       [[728,  13],\n",
       "        [ 11,   6]],\n",
       "\n",
       "       [[730,  11],\n",
       "        [  9,   8]],\n",
       "\n",
       "       [[735,   5],\n",
       "        [  3,  15]],\n",
       "\n",
       "       [[741,   5],\n",
       "        [  7,   5]],\n",
       "\n",
       "       [[731,   4],\n",
       "        [  6,  17]],\n",
       "\n",
       "       [[736,   6],\n",
       "        [  6,  10]],\n",
       "\n",
       "       [[730,   9],\n",
       "        [ 12,   7]],\n",
       "\n",
       "       [[741,   3],\n",
       "        [ 10,   4]],\n",
       "\n",
       "       [[738,   6],\n",
       "        [  3,  11]],\n",
       "\n",
       "       [[743,   2],\n",
       "        [  4,   9]],\n",
       "\n",
       "       [[747,   3],\n",
       "        [  0,   8]],\n",
       "\n",
       "       [[742,   4],\n",
       "        [  7,   5]],\n",
       "\n",
       "       [[744,   1],\n",
       "        [  9,   4]],\n",
       "\n",
       "       [[740,  10],\n",
       "        [  1,   7]],\n",
       "\n",
       "       [[743,   1],\n",
       "        [  4,  10]],\n",
       "\n",
       "       [[731,  12],\n",
       "        [  3,  12]]], dtype=int64)"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "72cf8973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6213720316622692"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "ebd124a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mtech.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "6543b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "573\n",
      "573\n"
     ]
    }
   ],
   "source": [
    "##-----------------Main Class for test--------------------------\n",
    "\n",
    "## 1. Reading Train Data from Excel Sheet\n",
    "CSV_DataFile = (\"E://Mtech_Project_Code//test_include50.csv\") \n",
    "\n",
    "test_data =open(CSV_DataFile)\n",
    "\n",
    "video_test,labelData_test=CSV_Files_To_Video_Paths(test_data)\n",
    "\n",
    "## 2. Weed out label and videos which can't be opened\n",
    "path_joiner = \"E://Mtech_Project_Code//Data//\"\n",
    "label_test=[]\n",
    "video_paths_test=[]\n",
    "sequences_test = []\n",
    "i=0\n",
    "for i in range(len(video_test)-1):\n",
    "    cap = cv2.VideoCapture(path_joiner+video_test[i])\n",
    "    if(cap.isOpened() == False):\n",
    "        print(\"------>Error opening the file :\", video_test[i])\n",
    "    else:\n",
    "        i=i+1\n",
    "        print(i)\n",
    "        test_sequence_list = feature_vector_extract_from_video(video_test[i])\n",
    "        for sequence in test_sequence_list:\n",
    "            sequences_test.append(sequence)\n",
    "            label_test.append(label_old[i])\n",
    "            video_paths_test.append(video_paths_old[i])\n",
    "\n",
    "print(len(label_test))\n",
    "print(len(video_paths_test))\n",
    "## 3. KeyPoints using MP Holistic\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "efa644dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(573, 138, 258)\n",
      "(573, 138, 258)\n",
      "(573, 154, 258)\n",
      "(573, 154, 258)\n",
      "(573,)\n",
      "[28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "padded_pre_test = pad_sequences(sequences_test, dtype='float64')\n",
    "padded_post_test = pad_sequences(sequences_test, padding= 'post', dtype='float64')\n",
    "truncated_pre_test = pad_sequences(sequences_test, maxlen=154, dtype='float64')\n",
    "truncated_post_test = pad_sequences(sequences_test, maxlen=154, truncating= 'post', dtype='float64')\n",
    "\n",
    "print(np.array(padded_pre_test).shape)\n",
    "print(np.array(padded_post_test).shape)\n",
    "print(np.array(truncated_pre_test).shape)\n",
    "print(np.array(truncated_post_test).shape)\n",
    "print(np.array(label_test).shape)\n",
    "label_testing=[]\n",
    "for i in range(len(label_test)):\n",
    "    label_testing.append(label_map[label_test[i]])\n",
    "    \n",
    "x_test=np.array(truncated_post_test)\n",
    "y_test=to_categorical(label_testing).astype(int)\n",
    "print(label_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3be9e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db3e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = svm.SVC(kernel = 'linear', C = 1)\n",
    "svm_classifier.fit(train_data, class_label)        \n",
    "filename = 'svm_model_num.sav'\n",
    "pickle.dump(svm_classifier, open(filename, 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
